{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "weave-evaluation",
  "_source": "https://docs.wandb.ai/weave/guides/core-types/evaluations",
  "_description": "Weave Evaluation structure for systematic agent assessment.",
  
  "evaluation_name": "agent-quality-v1",
  
  "dataset": {
    "_ref": "weave://entity/project/object/evaluation-examples:v1",
    "row_count": 50
  },
  
  // Scorers are @weave.op() decorated functions or Scorer subclasses in Python.
  // Represented here as metadata since JSON cannot express callables.
  "scorers": [
    {
      "name": "accuracy_score",
      "description": "Measures factual accuracy of response"
    },
    {
      "name": "completeness_score",
      "description": "Measures how completely the task was addressed"
    }
  ]

  // NOTE: Evaluation is a "blueprint" â€” it does NOT store results.
  // Results are returned from evaluation.evaluate(model).
  // See: https://docs.wandb.ai/weave/guides/core-types/evaluations#5-run-the-evaluation
}
